{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_pdf(url, file_name, headers):\n",
    "    # Send GET request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # Save the PDF\n",
    "    if response.status_code == 200:\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "if __name__ == \"__main__\":\n",
    "    # Define HTTP Headers\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Chrome/51.0.2704.103\",\n",
    "    }\n",
    "    # Define URL of an image\n",
    "    url = \"https://arxiv.org/ftp/arxiv/papers/1209/1209.6492.pdf\"\n",
    "    # Define image file name\n",
    "    file_name = \"file1.pdf\"\n",
    "    # Download image\n",
    "    download_pdf(url, file_name, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "in D. So for instance the 4 -shingling of            \n",
      "              (internet, scaled, data, storage, and, analysis)       \n",
      "is the set  \n",
      "{(internet, scaled, data, storage), (scaled, data, storage, and), \n",
      "(data , storage, and , analysis)}  \n",
      "Thus with each shingle a numerical score is associated which \n",
      "acts as a unique id for a particular shingle. This approach is \n",
      "called as fingerprinting. After fingerprinting each shingle in a \n",
      "document, the   document gets an associated set of nat ural \n",
      "number as unique ids for all the shingles. For example, if D is a \n",
      "document the S(D) will contain set  of all unique ids and size \n",
      "of S(D) is approximately equal to the number of words in the \n",
      "document D.  \n",
      "To calculate the resemblance between two document s A and B, \n",
      "we define r (A, B) as the resemblance factor and is calculated \n",
      "as below:  \n",
      "                           \n",
      "|S(A)  S(B)|r(A,B) = |S(A)  S(B)|\n",
      "  \n",
      "Here, r = resemblance factor between two documents  \n",
      "   \n",
      "= intersection operator  \n",
      "   \n",
      " = union operator  \n",
      "Experiments seem to indicate that high resemblance (that is \n",
      "close to 1) captures well the informal notion of ―near -\n",
      "duplicates‖ or ―roughly the same‖.  \n",
      " \n",
      "5. QUANTIFYING THE QUAL ITY OF \n",
      "RESULT  \n",
      "The result that we get from any information retrieval system \n",
      "needs to be evaluated to see how relevant it is. Thus, there is a \n",
      "need to quantify the quality of result using some evaluation \n",
      "measures. This type of evaluation can be done by submitting a \n",
      "batch of pre -fabricated queries to the  system and measure the \n",
      "relevance of results . \n",
      " \n",
      "5.1 Related work  \n",
      "The original  system -based  evaluations  were  the Cranfield  tests \n",
      "done  in the 1950s  and 1960s by Cyril Cleverdon, a librarian \n",
      "and computer scientist in the College of  Aeronautics  at \n",
      "Cranfield,  UK. Cleverdon  identified t wo broad  types  of \n",
      "―devices‖ that  affect effectiveness in  different  ways; he called  \n",
      "those  that increased  the proportion  of rel evant documents  \n",
      "among  those  retrieved ―precision  devices‖  and those that  \n",
      "increased  the proportion of  all relevant documents found  \n",
      "―recall  devices‖  [11]. Precision  and recall  devices  could  be \n",
      "combined in  different  ways to vary system beh aviour  in \n",
      "response  to user  queries;  the challenge  was measuring  the effect \n",
      "of any given combination.  \n",
      " \n",
      "These tests done by Cleverdon were one of the first system \n",
      "evaluation tests, later many other organisations performed \n",
      "more evaluations like Text REtrieval Conference (TREC), \n",
      "organized by researchers at NIST since 1992, performs system -\n",
      "based evaluations [ 12], as do similar evaluation venues such as \n",
      "NTCIR (NII Test Collections for Information Retrieval, \n",
      "organized by the National Institute of Informatics in Japan), \n",
      "CLEF (the Cross -Language Evaluation Forum organized by the \n",
      "Istituto di Scienza e Tecnologie dell ’Informazione), FIRE (the \n",
      "Forum for Information Retrieval Evaluation organized by the \n",
      "Information Retrieval  Society of India), and INEX (the \n",
      "INitiative for the Evaluation of XML Retrieval).  \n",
      "for a query, to filter the relevant documents from the retrieved \n",
      "result set etc. All these retrieval tasks are done from a vast \n",
      "collection of documents called as test collection. A test \n",
      "collection  encapsulates  the experimental  environment.  It is \n",
      "meant  to model  users  with information  needs  that are  particular  \n",
      "instances  or examples  of the task.  These  information  needs  are \n",
      "generally  treated  as if they do not  change over time;  if they are \n",
      "representat ive of the needs of  users  of the system in  general, \n",
      "then showing that  a system  can perform well  on them  suggests \n",
      "that a system  will perform  well.  \n",
      " \n",
      "Test collections  have three  components:  \n",
      " A corpus of documents to search;  \n",
      " A set of user information needs;  \n",
      " Judgement of the relevance of information needs to \n",
      "documents in the corpus.  \n",
      " \n",
      "5.3 Relevance Judgement  \n",
      "The relevance judgments  tell us which  documents  are relevant \n",
      "to each of the information needs.  As described ab ove, since  it \n",
      "is people  that will be using  the documents,  relevance is \n",
      "something  that must  be determined  by people.  The system  \n",
      "itself can  only try to predict  relevance;  an evaluation  \n",
      "determines  how good  the system  is at predicting  what  will be \n",
      "relevant, and an experiment  tells us whether  one system is  \n",
      "better  at it than anothe r. Once  the topics  have been  finalized, \n",
      "human  assessors  can start judging  documents  for relevance.  \n",
      "Assessors  read documents,  compare  them  to the topic  \n",
      "definition,  and say whether  they are rel evant or not (or possibly  \n",
      "how relevant they are). \n",
      "Exhaust ively judging  relevance—that is,  judging  every \n",
      "single  document  in the corpus  to every single  topic —is the  \n",
      "only way to guarantee that  all relevant documents  are known. \n",
      "This is often  impossible due  to time and budget  constraints, \n",
      "however. One assessor  judging  a million  documents  at a \n",
      "relatively quick  rate of 10 per  minute  would take over ten \n",
      "months  of 40-hour weeks  to complete  just one topic.  \n",
      "Focusing  judgment  effort on a small  portion  of the complete  \n",
      "corpus can  usually pr ovide enough  of the rel evant documents  \n",
      "for most  evaluation  and experimentation purposes.  One simple  \n",
      "approach  is the pooling  metho d: each topic  in the collection  is \n",
      "submitted  to a variety  of different  retrieval systems,  and the top \n",
      "N ranked documents from  all of those  systems  are pooled  for \n",
      "judging.   \n",
      " \n",
      "5.4 Evaluation  Measu res \n",
      "Once a  test collection  has been finalized,  at any time someone  \n",
      "may submit  a query der ived from  one of its topics  to a retrieval \n",
      "system,  obtain  the ranked list of retrieved documents,  and \n",
      "measure  the system ’s effectiveness using  the relevance \n",
      "judgments for  that topic.  The IR literature  is awash with \n",
      "different  evaluation measures  meant to  measure  different  \n",
      "aspects  of retrieval performance;  we will focus  on a few of the \n",
      "most  widely  used.  \n",
      " \n",
      "5.4.1 Precision  and Recall  \n",
      "Two of the most  basic  and most  important  aspects  of \n",
      "effectiveness centre  on the number  of relevant documents  \n",
      "retrieved: \n",
      "1. Precision: The total number of relevant documents in the \n",
      "retrieved set gives us the precision of the system . \n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"file1.pdf\")\n",
    "page = reader.pages[3]\n",
    "\n",
    "parts = []\n",
    "\n",
    "\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    y = tm[5]\n",
    "    if y > 50 and y < 720:\n",
    "        parts.append(text)\n",
    "\n",
    "\n",
    "page.extract_text(visitor_text=visitor_body)\n",
    "text_body = \"\".join(parts)\n",
    "\n",
    "print(text_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "url = 'https://www.sciencedaily.com/releases/2022/11/221129112837.htm'\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Walking can boost not only your own energy but also, potentially, the energy of your wearable electronic devices. Osaka Metropolitan University scientists made a significant advance toward self-charging wearable devices with their invention of a dynamic magnifier-enhanced piezoelectric vibration energy harvester that can amplify power generated from impulsive vibrations, such as from human walking, by about 90 times, while remaining as small as currently developed energy harvesters. The results were published in Applied Physics Letters.\\n\\nThese days, people carry multiple electronic devices such as smartphones, and wearable devices are expected to become increasingly widespread in the near future. The resulting demand for more efficient recharging of these devices has increased the attention paid to energy harvesting, a technology that converts energy such as heat and light into electricity that can power small devices. One form of energy harvesting called vibration energy harvesting is deemed highly practical given that it can transform the kinetic energy from vibration into electricity and is not affected by weather or climate.\\n\\nA research team led by Associate Professor Takeshi Yoshimura from the Graduate School of Engineering at Osaka Metropolitan University has developed a microelectromechanical system (MEMS) piezoelectric vibration energy harvester that is only approximately 2 cm in diameter with a U-shaped metal component called a dynamic magnifier. Compared with conventional harvesters, the new harvester allows for an increase of about 90 times in the power converted from impulsive vibrations, which can be generated by human walking motion.\\n\\nThe team has been working on developing vibration energy harvesters that utilize the piezoelectric effect, a phenomenon in which specific types of materials produce an electric charge or voltage in response to applied pressure. So far, they have succeeded in generating microwatt-level electricity from mechanical vibrations with a constant frequency, such as those generated by motors and washing machines. However, the power generation of these harvesters drops drastically when the applied vibrations are nonstationary and impulsive, such as those generated by human walking.\\n\\nResponding to this challenge, the team developed and incorporated the U-shaped vibration amplification component under the harvester. The component allowed for improvement in power generation without increasing the device size. The technology is expected to generate electric power from non-steady vibrations, including walking motion, in order to power small wearable devices such as smartphones and wireless earphones.\\n\\nProfessor Yoshimura concluded, \"Since electronic devices are expected to become more energy-efficient, we hope that this invention will contribute to the realization of self-charging wearable devices.\"'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, per):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forourcomparisons with Latent Semantic Analysis (LSA), weused theversion ofLSA in\\nwhich each wordcount,\\x19\\n\\x02,isreplaced by\\x1a\\x1c\\x1b\\x1e\\x1d\\n\\x0b\\x03\\x04\\x19\\n\\x02\\r\\x0c.This standard preprocessing trick slightly\\nimpro vestheretrie valperformance ofLSA bydown-weighting theinﬂuence ofveryfrequent\\nwords.\\nDuring thepretraining, theconfabulated activities ofthevisible units were computed using\\na“softmax” which isthegeneralization ofalogistic tomore than 2alternati ves:\\x00\\x01\\x03\\x02\\x05\\x04 \\x06\\x08\\x07\\n\\t\\n\\x0b\\x0e\\n\\x02\\r\\x0c\\x0e\\x10\\x0f\\x06\\x11\\x07\\n\\t\\n\\x0b\\x0e\\n\\x0f\\x0c (1)\\nwhere\\n\\x00\\x01\\x03\\x02isthemodeled probability ofword \\x12andLLE isnotasen-\\nsible method tousebecause itinvolvesﬁnding nearest neighbors inthehigh-dimensional space\\nforeach newquery document, butdocument retrie valdoes, atleast, giveusawayofassessing\\nhowgood thelow-dimensional codes are.Theuseofasoftmax does notaffectthelearning rule(4),but\\ntoallowforthefactthatthedocument contains \\x13observ ations from theprobability distrib ution\\noverwords, theweight \\x14\\n\\x02\\x16\\x15from word \\x12tofeatureAcomparison with Local Linear Embedding: Itishard tocompare autoencoders with Lo-\\ncalLinear Embedding (5)onareconstruction taskbecause, likeseveralother non-parametric di-\\nmensionality reduction methods, LLE does notgiveasimple wayofreconstructing atestimage.\\n\\x17wassettobe \\x13times theweight \\x14\\n\\x15\\x18\\x02from\\nthefeature totheword.\\nCommon stopw ords were remo vedfrom\\nthedocuments andtheremaining words were stemmed byremo ving common endings.\\nThedata wasrandomly split into\\n402,207 training and402,207 teststories, andthetraining setwasfurther randomly split into\\n302,207 training and100,000 validation documents.Fitting LLE takesatime thatisquadratic inthenum-\\nberoftraining cases, soweused the“20newsgroup” corpus thathasonly 11,314 training and\\n7,531 testdocuments.\\x10 \\x03 \\x00\\x05\\x10 \\x03 \\n\\x10 \\n\\t\\x00\\x05\\x10\\x11\\n \\n\\x10#\"\\x08\\x00andwealwaysreport\\n3As\\nfortheReuters corpus, weonly considered the2000 most frequent words inthetraining dataset.\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text_body, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03268e6a6edf64058914c3483354e384bb2ac295c10776263c3aa47ebedfcc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
